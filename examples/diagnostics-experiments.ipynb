{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "\n",
    "\n",
    "import trecs\n",
    "from trecs.models import ContentFiltering, ImplicitMF\n",
    "from trecs.random import Generator\n",
    "from trecs.metrics import MSEMeasurement, RecSimilarity, InteractionSimilarity, RecallMeasurement\n",
    "from trecs.components import Users\n",
    "import trecs.matrix_ops as mo #Note, in order for the ideal recommender to result in non-insane results, the normalize_users parameter in mo.inner_product must be set to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://web.ma.utexas.edu/users/mks/statmistakes/skeweddistributions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdealRecommender(ContentFiltering):\n",
    "    \"\"\"\n",
    "    With the Ideal Recommender, we make the *strong assumption* that the true scores are provided\n",
    "    to the recommender system through a custom scoring function, which always returns the true\n",
    "    underlying user-item scores. Therefore, this class is pretty much an empty skeleton; the only\n",
    "    modification is that we don't update any internal state of the recommender at each time step.\n",
    "    \n",
    "    Amy: Note to self, as a part of the baseline ContentFiltering class, if an actual_item_representation \n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "\n",
    "    def _update_internal_state(self, interactions):\n",
    "        # do not change users_hat!\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(1)\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams.update({'font.size': 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the dimensions small for easy visualization\n",
    "number_of_users = 5\n",
    "number_of_attributes = 10\n",
    "number_of_items = 15\n",
    "# We define user_representation using the standard integer generator in Numpy.\n",
    "# We assume a number of interactions with each attribute in the interval [0,4).\n",
    "\n",
    "users_shape = (number_of_users, number_of_attributes)\n",
    "actual_user_representation = Users(size=users_shape, num_users=number_of_users)\n",
    "model_user_representation = np.random.randint(4, size=(number_of_users, number_of_attributes))\n",
    "\n",
    "# We define item_representation using the Generator that comes with the framework\n",
    "# We assume a binary matrix with a binomial distribution\n",
    "\n",
    "actual_item_representation = Generator().binomial(\n",
    "    n=1, p=.3, size=(number_of_attributes, number_of_items)\n",
    ")\n",
    "\n",
    "model_item_representation = Generator().binomial(\n",
    "    n=1, p=.3, size=(number_of_attributes, number_of_items)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Not positive this is correct\n",
    "\n",
    "content = ContentFiltering(\n",
    "    num_users=number_of_users,\n",
    "    num_items=number_of_items,\n",
    "    num_attributes=number_of_attributes,\n",
    "    actual_user_representation=actual_user_representation,\n",
    "    user_representation=model_user_representation, \n",
    "    actual_item_representation = actual_item_representation,\n",
    "    item_representation=actual_item_representation, #model has the true item values\n",
    ")\n",
    "# add an MSE measurement\n",
    "content.add_metrics(MSEMeasurement(), RecallMeasurement())\n",
    "# Run for 5 time steps\n",
    "content.run(timesteps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal = IdealRecommender(\n",
    "    num_users=number_of_users,\n",
    "    num_items=number_of_items,\n",
    "    num_attributes=number_of_attributes,\n",
    "    actual_user_representation=actual_user_representation,\n",
    "    user_representation=actual_user_representation.actual_user_profiles.value, \n",
    "    actual_item_representation = actual_item_representation,\n",
    "    item_representation=actual_item_representation, #model has the true item values\n",
    "    num_items_per_iter=\"all\",\n",
    ")\n",
    "# add an MSE measurement\n",
    "ideal.add_metrics(MSEMeasurement(), RecallMeasurement())\n",
    "# Run for 5 time steps\n",
    "ideal.run(timesteps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = ImplicitMF(\n",
    "    num_users=number_of_users,\n",
    "    num_items=number_of_items,\n",
    "    num_latent_factors=number_of_attributes,\n",
    "    actual_user_representation=actual_user_representation,\n",
    "    actual_item_representation = actual_item_representation,\n",
    "    num_items_per_iter=3,\n",
    ")\n",
    "# add an MSE measurement\n",
    "mf.add_metrics(MSEMeasurement())\n",
    "# Run for 5 time steps\n",
    "#mf.run(timesteps=5,train_between_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 566.87it/s]\n"
     ]
    }
   ],
   "source": [
    "mf.run(timesteps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  4  6]\n",
      " [ 7  5 10]\n",
      " [14  4  3]\n",
      " [ 9  4 12]\n",
      " [ 2 14  1]]\n",
      "[[2.05797979 1.64575314 0.34811002]\n",
      " [2.29881233 1.03274101 0.8351257 ]\n",
      " [1.19390273 0.7576043  0.69827807]\n",
      " [1.40563245 1.22016358 1.05309238]\n",
      " [1.08373781 0.91814404 0.84650509]]\n",
      "[[2 1 0]\n",
      " [2 1 0]\n",
      " [2 1 0]\n",
      " [2 1 0]\n",
      " [2 1 0]]\n",
      "[[1 0]\n",
      " [2 1]\n",
      " [2 1]\n",
      " [2 1]\n",
      " [0 2]]\n",
      "[[ 4  1]\n",
      " [ 5  7]\n",
      " [ 4 14]\n",
      " [ 4  9]\n",
      " [14  2]]\n"
     ]
    }
   ],
   "source": [
    "#Testing recall stuff\n",
    "k=2\n",
    "shown_item_scores = np.take_along_axis(recommender.predicted_scores.value, recommender.items_shown, axis=1)\n",
    "\n",
    "shown_item_ranks = np.argsort(shown_item_scores, axis=1)\n",
    "#top_item_idxs = shown_item_ranks[:, recommender.items_shown.shape[1] - k:]\n",
    "top_item_idxs = shown_item_ranks[:, -k:]\n",
    "\n",
    "top_k_items = np.take_along_axis(recommender.items_shown, top_item_idxs, axis=1)\n",
    "\n",
    "#np.take_along_axis(recommender.users.actual_user_scores.value, top_item_ids, axis=1)\n",
    "\n",
    "print(recommender.items_shown)\n",
    "print(shown_item_scores)\n",
    "print(shown_item_ranks)\n",
    "print(top_item_ids)\n",
    "\n",
    "print(top_k_items)\n",
    "\n",
    "interactions = recommender.interactions.reshape(recommender.num_users, 1)\n",
    "print(interactions)\n",
    "recall = len(np.where(interactions == top_k_items)[0]) / recommender.num_users\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.14191380e+00  2.05797979e+00 -2.90734031e-01 -3.21875378e-01\n",
      "   1.64575314e+00 -2.55419443e-01  3.48110023e-01 -2.19369368e+00\n",
      "  -3.20387278e-01 -3.97012475e-01 -1.68412571e+00 -4.07926262e-01\n",
      "  -7.24148813e-02 -4.96943205e-01 -3.90776070e-01]\n",
      " [-1.35494813e+00 -5.62433259e-01 -4.31621749e-01 -2.16467514e+00\n",
      "  -3.76389433e-01  1.03274101e+00 -3.82748331e-01  2.29881233e+00\n",
      "  -4.87667695e-01 -2.24900883e+00  8.35125701e-01 -1.47733814e+00\n",
      "  -1.67646907e+00 -1.03272766e+00 -4.66855513e-01]\n",
      " [-1.64125219e+00  5.47461891e-01 -9.38897719e-01  6.98278073e-01\n",
      "   7.57604301e-01  1.44376519e-01  5.34723293e-01 -1.50289861e+00\n",
      "   3.23485875e-02 -2.27994456e-01  3.09597978e-01 -1.01968001e+00\n",
      "  -9.52203821e-01 -5.37110173e-01  1.19390273e+00]\n",
      " [ 7.08681698e-02  1.81433271e-01  4.06857147e-01 -1.82868970e-01\n",
      "   1.22016358e+00 -8.34681900e-02  5.01537684e-01 -9.93660517e-01\n",
      "  -8.90125184e-01  1.40563245e+00 -2.30809812e+00  8.38389488e-01\n",
      "   1.05309238e+00 -3.38738287e-01  7.52203389e-04]\n",
      " [-1.69679120e+00  8.46505085e-01  1.08373781e+00  7.62494567e-01\n",
      "   3.58438868e-02 -1.62224267e-01  7.16541961e-01 -2.00241247e-01\n",
      "   4.25586948e-01 -2.01142390e+00 -1.19518872e-01  1.91763656e-01\n",
      "   4.23402907e-01 -3.77399352e-01  9.18144041e-01]]\n",
      "[[ 1  4  6]\n",
      " [ 7  5 10]\n",
      " [14  4  3]\n",
      " [ 9  4 12]\n",
      " [ 2 14  1]]\n",
      "[[2.05797979 1.64575314 0.34811002]\n",
      " [2.29881233 1.03274101 0.8351257 ]\n",
      " [1.19390273 0.7576043  0.69827807]\n",
      " [1.40563245 1.22016358 1.05309238]\n",
      " [1.08373781 0.91814404 0.84650509]]\n",
      "[[2 1 0]\n",
      " [2 1 0]\n",
      " [2 1 0]\n",
      " [2 1 0]\n",
      " [2 1 0]]\n",
      "[[ 4  1]\n",
      " [ 5  7]\n",
      " [ 4 14]\n",
      " [ 4  9]\n",
      " [14  2]]\n",
      "[-1.35494813 -0.56243326 -0.43162175 -2.16467514 -0.37638943  1.03274101\n",
      " -0.38274833  2.29881233 -0.48766769 -2.24900883  0.8351257  -1.47733814\n",
      " -1.67646907 -1.03272766 -0.46685551]\n"
     ]
    }
   ],
   "source": [
    "shown_item_rel = np.take_along_axis(recommender.predicted_scores.value, recommender.items_shown, axis=1)\n",
    "#actual_rel = np.take_along_axis(recommender.users.actual_user_scores.value, recommender.items_shown, axis=1)\n",
    "\n",
    "\n",
    "shown_item_ranks = np.argsort(shown_item_rel, axis=1)\n",
    "print(recommender.predicted_scores.value)\n",
    "print(recommender.items_shown)\n",
    "print(shown_item_rel)\n",
    "print(shown_item_ranks)\n",
    "top_k_items = np.take_along_axis(recommender.items_shown, top_item_idxs, axis=1)\n",
    "print(top_k_items)\n",
    "\n",
    "print(recommender.predicted_scores.value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20081493 -0.62669818 -0.13549283  0.31272886  0.         -0.43569558\n",
      "   0.24622815 -0.37755385 -1.13868181  0.24763184 -0.31587262 -0.50090452\n",
      "  -0.51111674 -0.06713889 -0.43376564]\n",
      " [-0.31312586  0.06671706  0.11743417 -1.04139937  0.         -0.13851063\n",
      "  -0.31368262  0.57135809 -0.78673142 -0.32282974 -0.2721681  -1.09411609\n",
      "   0.17205193 -0.43886514 -0.65525096]\n",
      " [-0.67811974 -1.04852726  0.01136625  0.32997882  0.         -0.17514042\n",
      "   0.48465576 -0.15774528  0.18974285 -0.05955792 -0.29364017  0.12104795\n",
      "   0.15581012 -0.00600078  0.12704873]\n",
      " [ 1.14875318  0.35770991  0.25861001 -0.07594744  0.         -0.11691005\n",
      "   0.51411     0.62815202 -0.11672326  0.5481165   1.00268376  0.16662842\n",
      "   0.77158909  0.39871142 -0.23208299]\n",
      " [-0.15477756  0.23233256  0.11958448  0.05969266  0.         -0.28521795\n",
      "   0.31953653 -0.50131822 -0.04174253 -0.15995709 -0.44951751 -0.68637632\n",
      "  -1.07559972  0.29270762 -0.97908394]]\n",
      "[[ 1  4  6]\n",
      " [ 7  5 10]\n",
      " [14  4  3]\n",
      " [ 9  4 12]\n",
      " [ 2 14  1]]\n",
      "[[12.  2.  9. 15. 11.  5. 13.  7.  1. 14.  8.  4.  3. 10.  6.]\n",
      " [ 8. 12. 13.  2. 11. 10.  7. 15.  3.  6.  9.  1. 14.  5.  4.]\n",
      " [ 2.  1.  9. 14.  8.  4. 15.  5. 13.  6.  3. 10. 12.  7. 11.]\n",
      " [15.  8.  7.  4.  5.  2. 10. 12.  3. 11. 14.  6. 13.  9.  1.]\n",
      " [ 8. 13. 12. 11. 10.  6. 15.  4.  9.  7.  5.  3.  1. 14.  2.]]\n",
      "[[ 2. 11. 13.]\n",
      " [15. 10.  9.]\n",
      " [11.  8. 14.]\n",
      " [11.  5. 13.]\n",
      " [12.  2. 13.]]\n"
     ]
    }
   ],
   "source": [
    "print(recommender.users.actual_user_scores.value)\n",
    "print(recommender.items_shown)\n",
    "ranks = rankdata(recommender.users.actual_user_scores.value, axis=1)\n",
    "shown_ranks = np.take_along_axis(ranks, recommender.items_shown, axis=1)\n",
    "print(ranks)\n",
    "print(shown_ranks)\n",
    "#print(np.take_along_axis(recommender.items_shown, actual_rank, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        False,  True, False,  True,  True,  True],\n",
       "       [False,  True, False,  True, False,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True],\n",
       "       [ True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        False,  True,  True, False,  True,  True],\n",
       "       [ True,  True, False,  True,  True, False,  True,  True, False,\n",
       "         True,  True,  True,  True,  True, False],\n",
       "       [ True,  True, False,  True,  True,  True,  True, False, False,\n",
       "         True,  True,  True,  True, False,  True]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.isin(actual_rank, recommender.items_shown)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.62669818  0.          0.24622815]\n",
      " [ 0.57135809 -0.13851063 -0.2721681 ]\n",
      " [ 0.12704873  0.          0.32997882]\n",
      " [ 0.5481165   0.          0.77158909]\n",
      " [ 0.11958448 -0.97908394  0.23233256]]\n",
      "[[2 1 0]\n",
      " [0 1 2]\n",
      " [2 0 1]\n",
      " [2 0 1]\n",
      " [2 0 1]]\n",
      "[2.41545454 3.36796221 1.79512008 2.58740712 1.99409819]\n"
     ]
    }
   ],
   "source": [
    "#print(shown_item_rel[0])\n",
    "#print(shown_item_ranks)\n",
    "#print(shown_item_ranks+2)\n",
    "\n",
    "k=7\n",
    "recommender=mf\n",
    "\n",
    "#get the true relevance of the items shown\n",
    "shown_item_rel = np.take_along_axis(recommender.users.actual_user_scores.value, recommender.items_shown, axis=1)\n",
    "\n",
    "#reverse list because argsort sorts in ascending order (i.e., 0 rank to lowest value) and we need descending \n",
    "shown_item_ranks = np.flip(np.argsort(shown_item_rel, axis=1), axis=1)\n",
    "dcg = np.sum(shown_item_predicted_rel / np.log2(shown_item_ranks+2), axis=1)\n",
    "\n",
    "print(shown_item_rel)\n",
    "print(shown_item_ranks)\n",
    "\n",
    "\n",
    "print(dcg)\n",
    "\n",
    "#ideal_ranks=np.tile(np.arange(0,15),(recommender.num_users, recommender.num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.meshgrid(user_ids, item_ids)\n",
    "user_item_ids= np.dstack(np.meshgrid(item_ids, user_ids)).reshape(-1, 2)\n",
    "long_actual_scores = np.reshape(recommender.users.actual_user_scores.value, (recommender.num_users*recommender.num_items, 1))\n",
    "long_predicted_scores = np.reshape(recommender.predicted_scores.value, (recommender.num_users*recommender.num_items, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4,  6],\n",
       "       [ 7,  5, 10],\n",
       "       [14,  4,  3],\n",
       "       [ 9,  4, 12],\n",
       "       [ 2, 14,  1]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.items_shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual_scores</th>\n",
       "      <th>predicted_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200815</td>\n",
       "      <td>-1.141914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.626698</td>\n",
       "      <td>2.057980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.135493</td>\n",
       "      <td>-0.290734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312729</td>\n",
       "      <td>-0.321875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.645753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.435696</td>\n",
       "      <td>-0.255419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246228</td>\n",
       "      <td>0.348110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.377554</td>\n",
       "      <td>-2.193694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.138682</td>\n",
       "      <td>-0.320387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247632</td>\n",
       "      <td>-0.397012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315873</td>\n",
       "      <td>-1.684126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500905</td>\n",
       "      <td>-0.407926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.511117</td>\n",
       "      <td>-0.072415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.067139</td>\n",
       "      <td>-0.496943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.433766</td>\n",
       "      <td>-0.390776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.313126</td>\n",
       "      <td>-1.354948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_id  user_id  actual_scores  predicted_scores\n",
       "0       0.0      0.0       0.200815         -1.141914\n",
       "1       1.0      0.0      -0.626698          2.057980\n",
       "2       2.0      0.0      -0.135493         -0.290734\n",
       "3       3.0      0.0       0.312729         -0.321875\n",
       "4       4.0      0.0       0.000000          1.645753\n",
       "5       5.0      0.0      -0.435696         -0.255419\n",
       "6       6.0      0.0       0.246228          0.348110\n",
       "7       7.0      0.0      -0.377554         -2.193694\n",
       "8       8.0      0.0      -1.138682         -0.320387\n",
       "9       9.0      0.0       0.247632         -0.397012\n",
       "10     10.0      0.0      -0.315873         -1.684126\n",
       "11     11.0      0.0      -0.500905         -0.407926\n",
       "12     12.0      0.0      -0.511117         -0.072415\n",
       "13     13.0      0.0      -0.067139         -0.496943\n",
       "14     14.0      0.0      -0.433766         -0.390776\n",
       "15      0.0      1.0      -0.313126         -1.354948"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(np.hstack((user_item_ids, long_actual_scores, long_predicted_scores)), columns=['item_id', 'user_id', 'actual_scores', 'predicted_scores'])\n",
    "\n",
    "scores_df.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20081493 -0.62669818 -0.13549283  0.31272886  0.         -0.43569558\n",
      "   0.24622815 -0.37755385 -1.13868181  0.24763184 -0.31587262 -0.50090452\n",
      "  -0.51111674 -0.06713889 -0.43376564]\n",
      " [-0.31312586  0.06671706  0.11743417 -1.04139937  0.         -0.13851063\n",
      "  -0.31368262  0.57135809 -0.78673142 -0.32282974 -0.2721681  -1.09411609\n",
      "   0.17205193 -0.43886514 -0.65525096]\n",
      " [-0.67811974 -1.04852726  0.01136625  0.32997882  0.         -0.17514042\n",
      "   0.48465576 -0.15774528  0.18974285 -0.05955792 -0.29364017  0.12104795\n",
      "   0.15581012 -0.00600078  0.12704873]\n",
      " [ 1.14875318  0.35770991  0.25861001 -0.07594744  0.         -0.11691005\n",
      "   0.51411     0.62815202 -0.11672326  0.5481165   1.00268376  0.16662842\n",
      "   0.77158909  0.39871142 -0.23208299]\n",
      " [-0.15477756  0.23233256  0.11958448  0.05969266  0.         -0.28521795\n",
      "   0.31953653 -0.50131822 -0.04174253 -0.15995709 -0.44951751 -0.68637632\n",
      "  -1.07559972  0.29270762 -0.97908394]]\n",
      "[[ 0.20081493]\n",
      " [-0.62669818]\n",
      " [-0.13549283]\n",
      " [ 0.31272886]\n",
      " [ 0.        ]\n",
      " [-0.43569558]\n",
      " [ 0.24622815]\n",
      " [-0.37755385]\n",
      " [-1.13868181]\n",
      " [ 0.24763184]\n",
      " [-0.31587262]\n",
      " [-0.50090452]\n",
      " [-0.51111674]\n",
      " [-0.06713889]\n",
      " [-0.43376564]\n",
      " [-0.31312586]\n",
      " [ 0.06671706]\n",
      " [ 0.11743417]\n",
      " [-1.04139937]\n",
      " [ 0.        ]\n",
      " [-0.13851063]\n",
      " [-0.31368262]\n",
      " [ 0.57135809]\n",
      " [-0.78673142]\n",
      " [-0.32282974]\n",
      " [-0.2721681 ]\n",
      " [-1.09411609]\n",
      " [ 0.17205193]\n",
      " [-0.43886514]\n",
      " [-0.65525096]\n",
      " [-0.67811974]\n",
      " [-1.04852726]\n",
      " [ 0.01136625]\n",
      " [ 0.32997882]\n",
      " [ 0.        ]\n",
      " [-0.17514042]\n",
      " [ 0.48465576]\n",
      " [-0.15774528]\n",
      " [ 0.18974285]\n",
      " [-0.05955792]\n",
      " [-0.29364017]\n",
      " [ 0.12104795]\n",
      " [ 0.15581012]\n",
      " [-0.00600078]\n",
      " [ 0.12704873]\n",
      " [ 1.14875318]\n",
      " [ 0.35770991]\n",
      " [ 0.25861001]\n",
      " [-0.07594744]\n",
      " [ 0.        ]\n",
      " [-0.11691005]\n",
      " [ 0.51411   ]\n",
      " [ 0.62815202]\n",
      " [-0.11672326]\n",
      " [ 0.5481165 ]\n",
      " [ 1.00268376]\n",
      " [ 0.16662842]\n",
      " [ 0.77158909]\n",
      " [ 0.39871142]\n",
      " [-0.23208299]\n",
      " [-0.15477756]\n",
      " [ 0.23233256]\n",
      " [ 0.11958448]\n",
      " [ 0.05969266]\n",
      " [ 0.        ]\n",
      " [-0.28521795]\n",
      " [ 0.31953653]\n",
      " [-0.50131822]\n",
      " [-0.04174253]\n",
      " [-0.15995709]\n",
      " [-0.44951751]\n",
      " [-0.68637632]\n",
      " [-1.07559972]\n",
      " [ 0.29270762]\n",
      " [-0.97908394]]\n"
     ]
    }
   ],
   "source": [
    "#recommender.users.actual_user_scores.value.shape\n",
    "user_ids = np.arange(0, recommender.num_users)\n",
    "item_ids = np.arange(0, recommender.num_items)\n",
    "\n",
    "long_actual_scores = np.reshape(recommender.users.actual_user_scores.value, (recommender.num_users*recommender.num_items, 1))\n",
    "\n",
    "print(recommender.users.actual_user_scores.value)\n",
    "print(long_actual_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.62669818  0.          0.24622815]\n",
      " [ 0.57135809 -0.13851063 -0.2721681 ]\n",
      " [ 0.12704873  0.          0.32997882]\n",
      " [ 0.5481165   0.          0.77158909]\n",
      " [ 0.11958448 -0.97908394  0.23233256]]\n",
      "[[2.05797979 1.64575314 0.34811002]\n",
      " [2.29881233 1.03274101 0.8351257 ]\n",
      " [1.19390273 0.7576043  0.69827807]\n",
      " [1.40563245 1.22016358 1.05309238]\n",
      " [1.08373781 0.91814404 0.84650509]]\n",
      "[[3. 2. 1.]\n",
      " [1. 2. 3.]\n",
      " [3. 1. 2.]\n",
      " [3. 1. 2.]\n",
      " [3. 1. 2.]]\n",
      "[[1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]]\n",
      "[-0.50358411  0.34788356  0.29203814  0.93391104 -0.38198243]\n",
      "[-0.06712094  0.34788356  0.27171782  0.76087676 -0.77270617]\n"
     ]
    }
   ],
   "source": [
    "shown_item_actual_rel = np.take_along_axis(recommender.users.actual_user_scores.value, recommender.items_shown, axis=1)\n",
    "shown_item_predicted_rel = np.take_along_axis(recommender.predicted_scores.value, recommender.items_shown, axis=1)\n",
    "\n",
    "#flip so rank 1 corresponds to the highest value\n",
    "shown_item_predicted_rank = np.flip(rankdata(shown_item_predicted_rel, axis=1), axis=1)\n",
    "shown_item_actual_rank = np.flip(rankdata(shown_item_actual_rel, axis=1), axis=1)\n",
    "\n",
    "print(shown_item_actual_rel)\n",
    "print(shown_item_predicted_rel)\n",
    "print(shown_item_actual_rank)\n",
    "print(shown_item_predicted_rank)\n",
    "\n",
    "dcg = np.sum(shown_item_actual_rel / np.log2(shown_item_predicted_rank+1), axis=1)\n",
    "idcg = np.sum(shown_item_actual_rel / np.log2(shown_item_actual_rank+1), axis=1)\n",
    "\n",
    "print(dcg)\n",
    "print(idcg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20081493 -0.62669818 -0.13549283  0.31272886  0.         -0.43569558\n",
      "   0.24622815 -0.37755385 -1.13868181  0.24763184 -0.31587262 -0.50090452\n",
      "  -0.51111674 -0.06713889 -0.43376564]\n",
      " [-0.31312586  0.06671706  0.11743417 -1.04139937  0.         -0.13851063\n",
      "  -0.31368262  0.57135809 -0.78673142 -0.32282974 -0.2721681  -1.09411609\n",
      "   0.17205193 -0.43886514 -0.65525096]\n",
      " [-0.67811974 -1.04852726  0.01136625  0.32997882  0.         -0.17514042\n",
      "   0.48465576 -0.15774528  0.18974285 -0.05955792 -0.29364017  0.12104795\n",
      "   0.15581012 -0.00600078  0.12704873]\n",
      " [ 1.14875318  0.35770991  0.25861001 -0.07594744  0.         -0.11691005\n",
      "   0.51411     0.62815202 -0.11672326  0.5481165   1.00268376  0.16662842\n",
      "   0.77158909  0.39871142 -0.23208299]\n",
      " [-0.15477756  0.23233256  0.11958448  0.05969266  0.         -0.28521795\n",
      "   0.31953653 -0.50131822 -0.04174253 -0.15995709 -0.44951751 -0.68637632\n",
      "  -1.07559972  0.29270762 -0.97908394]]\n",
      "[[ 8  1 12 11  5 14  7 10  2 13  4  0  6  9  3]\n",
      " [11  3  8 14 13  9  6  0 10  5  4  1  2 12  7]\n",
      " [ 1  0 10  5  7  9 13  4  2 11 14 12  8  3  6]\n",
      " [14  5  8  3  4 11  2  1 13  6  9  7 12 10  0]\n",
      " [12 14 11  7 10  5  9  0  8  4  3  2  1 13  6]]\n",
      "[[0.24622815 0.24763184 0.31272886]\n",
      " [0.11743417 0.17205193 0.57135809]\n",
      " [0.18974285 0.32997882 0.48465576]\n",
      " [0.77158909 1.00268376 1.14875318]\n",
      " [0.23233256 0.29270762 0.31953653]]\n",
      "[[0 1 2]\n",
      " [0 1 2]\n",
      " [0 1 2]\n",
      " [0 1 2]\n",
      " [0 1 2]]\n",
      "[0.55883088 0.5116659  0.64026419 1.9785887  0.57677877]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "ranks = rankdata(recommender.users.actual_user_scores.value, axis=1)\n",
    "shown_ranks = np.take_along_axis(ranks, recommender.items_shown, axis=1)\n",
    "\n",
    "#get an array that would ideally sort the items per users' actual preferences\n",
    "ideal_rank = np.argsort(recommender.users.actual_user_scores.value)\n",
    "\n",
    "#take the last n items of ideal_rank, which gives the indices of the best items\n",
    "ideal_item_idxs = ideal_rank[:,-recommender.items_shown.shape[1]:]\n",
    "\n",
    "#get the actual relevance scores for the best n items (i.e., those in ideal_item_idxs)\n",
    "ideal_item_rel = np.take_along_axis(recommender.users.actual_user_scores.value, ideal_item_idxs, axis=1)\n",
    "\n",
    "ideal_ranks=np.tile(np.arange(0,recommender.items_shown.shape[1]),(recommender.num_users, 1))\n",
    "\n",
    "idcg = np.sum(ideal_item_rel / np.log2(ideal_ranks+2), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(recommender.users.actual_user_scores.value)\n",
    "print(ideal_rank)\n",
    "print(ideal_item_rel)\n",
    "print(ideal_ranks)\n",
    "print(idcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  9,  3],\n",
       "       [ 2, 12,  7],\n",
       "       [ 8,  3,  6],\n",
       "       [12, 10,  0],\n",
       "       [ 1, 13,  6]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_item_ranks[:, recommender.num_items-recommender.items_shown.shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20081493, -0.62669818, -0.13549283,  0.31272886,  0.        ,\n",
       "        -0.43569558,  0.24622815, -0.37755385, -1.13868181,  0.24763184,\n",
       "        -0.31587262, -0.50090452, -0.51111674, -0.06713889, -0.43376564],\n",
       "       [-0.31312586,  0.06671706,  0.11743417, -1.04139937,  0.        ,\n",
       "        -0.13851063, -0.31368262,  0.57135809, -0.78673142, -0.32282974,\n",
       "        -0.2721681 , -1.09411609,  0.17205193, -0.43886514, -0.65525096],\n",
       "       [-0.67811974, -1.04852726,  0.01136625,  0.32997882,  0.        ,\n",
       "        -0.17514042,  0.48465576, -0.15774528,  0.18974285, -0.05955792,\n",
       "        -0.29364017,  0.12104795,  0.15581012, -0.00600078,  0.12704873],\n",
       "       [ 1.14875318,  0.35770991,  0.25861001, -0.07594744,  0.        ,\n",
       "        -0.11691005,  0.51411   ,  0.62815202, -0.11672326,  0.5481165 ,\n",
       "         1.00268376,  0.16662842,  0.77158909,  0.39871142, -0.23208299],\n",
       "       [-0.15477756,  0.23233256,  0.11958448,  0.05969266,  0.        ,\n",
       "        -0.28521795,  0.31953653, -0.50131822, -0.04174253, -0.15995709,\n",
       "        -0.44951751, -0.68637632, -1.07559972,  0.29270762, -0.97908394]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.users.actual_user_scores.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.20081493 -0.62669818 -0.13549283  0.31272886  0.         -0.43569558\n",
      "  0.24622815 -0.37755385 -1.13868181  0.24763184 -0.31587262 -0.50090452\n",
      " -0.51111674 -0.06713889 -0.43376564]\n",
      "[-0.31312586  0.06671706  0.11743417 -1.04139937  0.         -0.13851063\n",
      " -0.31368262  0.57135809 -0.78673142 -0.32282974 -0.2721681  -1.09411609\n",
      "  0.17205193 -0.43886514 -0.65525096]\n",
      "[-0.67811974 -1.04852726  0.01136625  0.32997882  0.         -0.17514042\n",
      "  0.48465576 -0.15774528  0.18974285 -0.05955792 -0.29364017  0.12104795\n",
      "  0.15581012 -0.00600078  0.12704873]\n",
      "[ 8  1 12 11  5 14  7 10  2 13  4  0  6  9  3]\n",
      "[11  3  8 14 13  9  6  0 10  5  4  1  2 12  7]\n",
      "[ 1  0 10  5  7  9 13  4  2 11 14 12  8  3  6]\n",
      "[[ 6  9  3]\n",
      " [ 2 12  7]\n",
      " [ 8  3  6]\n",
      " [12 10  0]\n",
      " [ 1 13  6]]\n"
     ]
    }
   ],
   "source": [
    "k=3\n",
    "recommender=mf\n",
    "\n",
    "\n",
    "actual_item_ranks = np.argsort(recommender.users.actual_user_scores.value, axis=1)\n",
    "#Take the number of users' actual top items according to the number recommended per iteration\n",
    "#actual_top_k_items = np.take(recommender.items_shown, shown_item_ranks[:, recommender.num_items-recommender.items_shown.shape[1]:])\n",
    "\n",
    "#actual_top_k_rel = np.take(recommender.users.actual_user_scores.value, actual_item_ranks[:, recommender.num_items-recommender.items_shown.shape[1]:])\n",
    "top_item_ids = actual_item_ranks[:, recommender.num_items-recommender.items_shown.shape[1]:]\n",
    "top_item_rel = np.take_along_axis(recommender.users.actual_user_scores.value, top_item_ids, axis=1)\n",
    "\n",
    "\n",
    "# print(recommender.users.actual_user_scores.value[0])\n",
    "# print(recommender.users.actual_user_scores.value[1])\n",
    "# print(recommender.users.actual_user_scores.value[2])\n",
    "\n",
    "# print(actual_item_ranks[0])\n",
    "# print(actual_item_ranks[1])\n",
    "# print(actual_item_ranks[2])\n",
    "\n",
    "# print(top_item_ids)\n",
    "\n",
    "# #print(actual_item_ranks[0:2])\n",
    "# print(actual_item_ranks[0:2, recommender.num_items-recommender.items_shown.shape[1]:])\n",
    "\n",
    "# print(actual_top_k_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2, ..., 12, 13, 14],\n",
       "       [ 0,  1,  2, ..., 12, 13, 14],\n",
       "       [ 0,  1,  2, ..., 12, 13, 14],\n",
       "       [ 0,  1,  2, ..., 12, 13, 14],\n",
       "       [ 0,  1,  2, ..., 12, 13, 14]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal_ranks=np.tile(np.arange(0,15),(recommender.num_users, recommender.num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24622815, 0.24763184, 0.31272886],\n",
       "       [0.11743417, 0.17205193, 0.57135809],\n",
       "       [0.18974285, 0.32997882, 0.48465576],\n",
       "       [0.77158909, 1.00268376, 1.14875318],\n",
       "       [0.23233256, 0.29270762, 0.31953653]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take_along_axis(recommender.users.actual_user_scores.value, top_item_ids, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  9,  3],\n",
       "       [ 2, 12,  7],\n",
       "       [ 8,  3,  6],\n",
       "       [12, 10,  0],\n",
       "       [ 1, 13,  6]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_item_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mf.users.actual_user_scores.shape)\n",
    "print(mf.predicted_user_item_scores.shape)\n",
    "\n",
    "actual = np.reshape(mf.users.actual_user_scores.value, (number_of_users*number_of_items, 1))\n",
    "predicted = np.reshape(mf.predicted_user_item_scores, (number_of_users*number_of_items, 1))\n",
    "print(test.shape)\n",
    "\n",
    "plt.hist(actual, alpha=0.7)\n",
    "plt.hist(predicted, alpha=0.7)#predicted scores are more spread out, which kind of makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_error = abs(actual-predicted)\n",
    "\n",
    "plt.hist(abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect measurements about the simulation\n",
    "results = mf.get_measurements()\n",
    "\n",
    "print(\"Results of the simulation:\")\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect measurements about the simulation\n",
    "results = ideal.get_measurements()\n",
    "\n",
    "print(\"Results of the simulation:\")\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = content.get_measurements()\n",
    "\n",
    "print(\"Results of the simulation:\")\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a distribution that hides a subpopulation\n",
    "number_of_attributes = 10\n",
    "number_of_maj_users = 150\n",
    "number_of_min_users = 50\n",
    "\n",
    "maj_user_representation = np.random.normal(1, 2, size=(number_of_maj_users, number_of_attributes))\n",
    "min_user_representation = np.random.normal(0.5, 1.25, size=(number_of_min_users, number_of_attributes))\n",
    "actual_user_representation = np.vstack((maj_user_representation, min_user_representation))\n",
    "split_indices=number_of_maj_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If plotted without respect to the subgroups, preference means look more or less normally distributed\n",
    "plt.hist(actual_user_representation.mean(axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when plotting out mean preferences when accounting for group, we can see a clear distinction in preference\n",
    "plt.hist(maj_user_representation.mean(axis=1), alpha=.7, color='b')\n",
    "plt.hist(min_user_representation.mean(axis=1), alpha=0.7, color='r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering = ContentFiltering(actual_user_representation=actual_user_representation, \n",
    "                             num_attributes=number_of_attributes,\n",
    "                             num_items=500)\n",
    "\n",
    "\n",
    "mse = MSEMeasurement(diagnostics=True)\n",
    "recall=RecallMeasurement()\n",
    "\n",
    "filtering.add_metrics(mse, recall)\n",
    "\n",
    "filtering.startup_and_train(50)\n",
    "filtering.run(450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_diagnostics = filtering.metrics[0].get_diagnostics()\n",
    "mse_beginning = mse_diagnostics.loc[50:, :]\n",
    "mse_beginning.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_histogram(model, split_indices=None):\n",
    "    metric = (\n",
    "                model.predicted_scores.value.mean(axis=1)- model.users.actual_user_scores.value.mean(axis=1))** 2\n",
    "    \n",
    "    colors = [\"blue\", \"orange\", \"red\", \"yellow\", \"green\"]\n",
    "    if split_indices is not None and len(split_indices) > 0:\n",
    "        splits = [0] + split_indices + [metric.size]\n",
    "        for i in range(len(splits) - 1):\n",
    "            values = metric[splits[i] : splits[i + 1]]\n",
    "            plt.hist(values, alpha=0.7, color=colors[i])\n",
    "    else:\n",
    "        plt.hist(metric, bins=\"auto\")\n",
    "        plt.ylabel(\"observation count (total n={})\".format(metric.size))\n",
    "        plt.xlabel(\"mean sqaured error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.startup_and_train(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_histogram(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.run(50)\n",
    "mf.train()\n",
    "mse_histogram(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.run(50)\n",
    "mf.train()\n",
    "mse_histogram(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.run(50)\n",
    "mf.train()\n",
    "mse_histogram(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.run(50)\n",
    "mse_histogram(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.run(50)\n",
    "mse_histogram(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(in_k)\n",
    "print(not_in_k)\n",
    "print(len(model.interactions))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.concatenate((np.ones(len(in_k)), np.zeros(len(not_in_k))), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=mf\n",
    "k=5\n",
    "\n",
    "#split_indices = number_of_maj_users\n",
    "\n",
    "colors = [\"blue\", \"orange\", \"red\", \"yellow\", \"green\"]\n",
    "\n",
    "shown_item_scores = np.take(model.predicted_scores.value, model.items_shown)\n",
    "shown_item_ranks = np.argsort(shown_item_scores, axis=1)\n",
    "top_k_items = np.take(model.items_shown, shown_item_ranks[:, k :])\n",
    "in_k = (np.where(np.isin(model.interactions, top_k_items))[0])\n",
    "not_in_k = (np.where(~np.isin(model.interactions, top_k_items))[0])\n",
    "metric = np.concatenate((np.ones(len(in_k)), np.zeros(len(not_in_k))), axis=None)\n",
    "\n",
    "plt.hist(metric)\n",
    "\n",
    "##Amy, implement this pie chart for recall at k\n",
    "# # Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "# labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n",
    "# sizes = [15, 30, 45, 10]\n",
    "# explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "#         shadow=True, startangle=90)\n",
    "# ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# maj_population_outcomes = metric[:split_indices]\n",
    "# min_population_outcomes = metric[split_indices:]\n",
    "\n",
    "# plt.hist(maj_population_outcomes, color=colors[0])\n",
    "# plt.hist(min_population_outcomes, color=colors[1])\n",
    "\n",
    "\n",
    "\n",
    "# if split_indices is not None:\n",
    "#     splits = [0] + split_indices + [metric.size]\n",
    "#     for i in range(len(splits) - 1):\n",
    "#         values = metric[splits[i] : splits[i + 1]]\n",
    "#         plt.hist(values, alpha=0.7, color=colors[i])\n",
    "\n",
    "# plt.hist(metric, bins=\"auto\")\n",
    "# plt.ylabel(\"observation count (total n={})\".format(metric.size))\n",
    "# plt.xlabel(\"recall at k\")\n",
    "\n",
    "\n",
    "# \n",
    "#     if split_indices is not None and len(split_indices) > 0:\n",
    "#         splits = [0] + split_indices + [metric.size]\n",
    "#         for i in range(len(splits) - 1):\n",
    "#             values = metric[splits[i] : splits[i + 1]]\n",
    "#             plt.hist(values, alpha=0.7, color=colors[i])\n",
    "#     else:\n",
    "#         plt.hist(metric, bins=\"auto\")\n",
    "#         plt.ylabel(\"observation count (total n={})\".format(metric.size))\n",
    "#         plt.xlabel(\"mean sqaured error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(min_population_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(min_population_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_histogram(filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_histogram(filtering, [number_of_maj_users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a bimodal distribution\n",
    "N=500\n",
    "mu, sigma = 1.845, 1\n",
    "mu2, sigma2 = 5.845, 1\n",
    "X1 = np.random.normal(mu, sigma, N)\n",
    "X2 = np.random.normal(mu2, sigma2, N)\n",
    "X_bimodal = np.concatenate([X1, X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print majority / minority outcome stats\n",
    "def majority_minority_outcomes(metric, split_index):\n",
    "    split_indices = [split_index]\n",
    "\n",
    "        \n",
    "    maj_mean = metric.last_observation[:split_index].mean()\n",
    "    maj_std = metric.last_observation[:split_index].std()\n",
    "\n",
    "    min_mean = metric.last_observation[split_index:].mean()\n",
    "    min_std = metric.last_observation[split_index:].std()\n",
    "\n",
    "    print(\"Majority group statistics: \", maj_mean, \"(mean), \", maj_std, \"(std)\")\n",
    "    print(\"Minority group statistics: \", min_mean, \"(mean), \", min_std, \"(std)\")\n",
    "    print()\n",
    "    \n",
    "    metric.hist(split_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we expand on this minimal example to gain a deeper understanding of what happens under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering = ContentFiltering(actual_user_representation=actual_user_representation, \n",
    "                             num_attributes=number_of_attributes,\n",
    "                             num_items=500)\n",
    "\n",
    "\n",
    "mse = MSEMeasurement(diagnostics=True)\n",
    "filtering.add_metrics(mse)\n",
    "\n",
    "filtering.startup_and_train(50)\n",
    "majority_minority_outcomes(mse, number_of_maj_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering.run(450)\n",
    "majority_minority_outcomes(mse, number_of_maj_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bimodal = plt.hist(X_bimodal, bins=30)\n",
    "plt.xlabel('Dependent Variable Value')\n",
    "plt.ylabel('Number of Observations')\n",
    "plt.title('Bimodal Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X_bimodal))\n",
    "print(np.std(X_bimodal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000\n",
    "mu, sigma = 14.99, 4\n",
    "X1 = np.random.normal(mu, sigma, N)\n",
    "X_skew = np.log2(X1)\n",
    "\n",
    "skew = plt.hist(X_skew, bins=30)\n",
    "plt.xlabel('Dependent Variable Value')\n",
    "plt.ylabel('Number of Observations')\n",
    "plt.title('Skewed Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000\n",
    "mu, sigma = 3.85, 2.2\n",
    "normal_dist = np.random.normal(mu, sigma, N)\n",
    "\n",
    "skew = plt.hist(normal_dist, bins=30)\n",
    "plt.xlabel('Dependent Variable Value')\n",
    "plt.ylabel('Number of Observations')\n",
    "plt.title('Normal Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to characterize power, type 1 vs type 2 errors "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trecsEnv",
   "language": "python",
   "name": "trecsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

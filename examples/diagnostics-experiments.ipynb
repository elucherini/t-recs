{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import trecs\n",
    "from trecs.models import ContentFiltering, ImplicitMF\n",
    "from trecs.random import Generator\n",
    "from trecs.metrics import MSEMeasurement, RecSimilarity, InteractionSimilarity, RecallMeasurement\n",
    "from trecs.components import Users\n",
    "import trecs.matrix_ops as mo #Note, in order for the ideal recommender to result in non-insane results, the normalize_users parameter in mo.inner_product must be set to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://web.ma.utexas.edu/users/mks/statmistakes/skeweddistributions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdealRecommender(ContentFiltering):\n",
    "    \"\"\"\n",
    "    With the Ideal Recommender, we make the *strong assumption* that the true scores are provided\n",
    "    to the recommender system through a custom scoring function, which always returns the true\n",
    "    underlying user-item scores. Therefore, this class is pretty much an empty skeleton; the only\n",
    "    modification is that we don't update any internal state of the recommender at each time step.\n",
    "    \n",
    "    Amy: Note to self, as a part of the baseline ContentFiltering class, if an actual_item_representation \n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "\n",
    "    def _update_internal_state(self, interactions):\n",
    "        # do not change users_hat!\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(1)\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams.update({'font.size': 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the dimensions small for easy visualization\n",
    "number_of_users = 5\n",
    "number_of_attributes = 10\n",
    "number_of_items = 15\n",
    "# We define user_representation using the standard integer generator in Numpy.\n",
    "# We assume a number of interactions with each attribute in the interval [0,4).\n",
    "\n",
    "users_shape = (number_of_users, number_of_attributes)\n",
    "actual_user_representation = Users(size=users_shape, num_users=number_of_users)\n",
    "model_user_representation = np.random.randint(4, size=(number_of_users, number_of_attributes))\n",
    "\n",
    "# We define item_representation using the Generator that comes with the framework\n",
    "# We assume a binary matrix with a binomial distribution\n",
    "\n",
    "actual_item_representation = Generator().binomial(\n",
    "    n=1, p=.3, size=(number_of_attributes, number_of_items)\n",
    ")\n",
    "\n",
    "model_item_representation = Generator().binomial(\n",
    "    n=1, p=.3, size=(number_of_attributes, number_of_items)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Not positive this is correct\n",
    "\n",
    "content = ContentFiltering(\n",
    "    num_users=number_of_users,\n",
    "    num_items=number_of_items,\n",
    "    num_attributes=number_of_attributes,\n",
    "    actual_user_representation=actual_user_representation,\n",
    "    user_representation=model_user_representation, \n",
    "    actual_item_representation = actual_item_representation,\n",
    "    item_representation=actual_item_representation, #model has the true item values\n",
    ")\n",
    "# add an MSE measurement\n",
    "content.add_metrics(MSEMeasurement(), RecallMeasurement())\n",
    "# Run for 5 time steps\n",
    "content.run(timesteps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal = IdealRecommender(\n",
    "    num_users=number_of_users,\n",
    "    num_items=number_of_items,\n",
    "    num_attributes=number_of_attributes,\n",
    "    actual_user_representation=actual_user_representation,\n",
    "    user_representation=actual_user_representation.actual_user_profiles.value, \n",
    "    actual_item_representation = actual_item_representation,\n",
    "    item_representation=actual_item_representation, #model has the true item values\n",
    "    num_items_per_iter=\"all\",\n",
    ")\n",
    "# add an MSE measurement\n",
    "ideal.add_metrics(MSEMeasurement(), RecallMeasurement())\n",
    "# Run for 5 time steps\n",
    "ideal.run(timesteps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = ImplicitMF(\n",
    "    num_users=number_of_users,\n",
    "    num_items=number_of_items,\n",
    "    num_latent_factors=number_of_attributes,\n",
    "    actual_user_representation=actual_user_representation,\n",
    "    actual_item_representation = actual_item_representation,\n",
    "    num_items_per_iter=3,\n",
    ")\n",
    "# add an MSE measurement\n",
    "mf.add_metrics(MSEMeasurement())\n",
    "# Run for 5 time steps\n",
    "#mf.run(timesteps=5,train_between_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 566.87it/s]\n"
     ]
    }
   ],
   "source": [
    "mf.run(timesteps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.14191380e+00  2.05797979e+00 -2.90734031e-01 -3.21875378e-01\n",
      "   1.64575314e+00 -2.55419443e-01  3.48110023e-01 -2.19369368e+00\n",
      "  -3.20387278e-01 -3.97012475e-01 -1.68412571e+00 -4.07926262e-01\n",
      "  -7.24148813e-02 -4.96943205e-01 -3.90776070e-01]\n",
      " [-1.35494813e+00 -5.62433259e-01 -4.31621749e-01 -2.16467514e+00\n",
      "  -3.76389433e-01  1.03274101e+00 -3.82748331e-01  2.29881233e+00\n",
      "  -4.87667695e-01 -2.24900883e+00  8.35125701e-01 -1.47733814e+00\n",
      "  -1.67646907e+00 -1.03272766e+00 -4.66855513e-01]\n",
      " [-1.64125219e+00  5.47461891e-01 -9.38897719e-01  6.98278073e-01\n",
      "   7.57604301e-01  1.44376519e-01  5.34723293e-01 -1.50289861e+00\n",
      "   3.23485875e-02 -2.27994456e-01  3.09597978e-01 -1.01968001e+00\n",
      "  -9.52203821e-01 -5.37110173e-01  1.19390273e+00]\n",
      " [ 7.08681698e-02  1.81433271e-01  4.06857147e-01 -1.82868970e-01\n",
      "   1.22016358e+00 -8.34681900e-02  5.01537684e-01 -9.93660517e-01\n",
      "  -8.90125184e-01  1.40563245e+00 -2.30809812e+00  8.38389488e-01\n",
      "   1.05309238e+00 -3.38738287e-01  7.52203389e-04]\n",
      " [-1.69679120e+00  8.46505085e-01  1.08373781e+00  7.62494567e-01\n",
      "   3.58438868e-02 -1.62224267e-01  7.16541961e-01 -2.00241247e-01\n",
      "   4.25586948e-01 -2.01142390e+00 -1.19518872e-01  1.91763656e-01\n",
      "   4.23402907e-01 -3.77399352e-01  9.18144041e-01]]\n",
      "[[ 1  4  6]\n",
      " [ 7  5 10]\n",
      " [14  4  3]\n",
      " [ 9  4 12]\n",
      " [ 2 14  1]]\n",
      "[[2.05797979 1.64575314 0.34811002]\n",
      " [2.29881233 1.03274101 0.8351257 ]\n",
      " [1.19390273 0.7576043  0.69827807]\n",
      " [1.40563245 1.22016358 1.05309238]\n",
      " [1.08373781 0.91814404 0.84650509]]\n",
      "[-1.6967912   0.84650509  1.08373781  0.76249457  0.03584389 -0.16222427\n",
      "  0.71654196 -0.20024125  0.42558695 -2.0114239  -0.11951887  0.19176366\n",
      "  0.42340291 -0.37739935  0.91814404]\n"
     ]
    }
   ],
   "source": [
    "print(recommender.predicted_scores.value)\n",
    "print(recommender.items_shown)\n",
    "\n",
    "print(shown_item_scores)\n",
    "\n",
    "print(recommender.predicted_scores.value[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  4  6]\n",
      " [ 7  5 10]\n",
      " [14  4  3]\n",
      " [ 9  4 12]\n",
      " [ 2 14  1]]\n",
      "[[2.05797979 1.64575314 0.34811002]\n",
      " [2.29881233 1.03274101 0.8351257 ]\n",
      " [1.19390273 0.7576043  0.69827807]\n",
      " [1.40563245 1.22016358 1.05309238]\n",
      " [1.08373781 0.91814404 0.84650509]]\n",
      "[[2 1 0]\n",
      " [2 1 0]\n",
      " [2 1 0]\n",
      " [2 1 0]\n",
      " [2 1 0]]\n",
      "[[1 0]\n",
      " [2 1]\n",
      " [2 1]\n",
      " [2 1]\n",
      " [0 2]]\n",
      "[[ 4  1]\n",
      " [ 5  7]\n",
      " [ 4 14]\n",
      " [ 4  9]\n",
      " [14  2]]\n"
     ]
    }
   ],
   "source": [
    "#Testing recall stuff\n",
    "k=2\n",
    "shown_item_scores = np.take_along_axis(recommender.predicted_scores.value, recommender.items_shown, axis=1)\n",
    "\n",
    "shown_item_ranks = np.argsort(shown_item_scores, axis=1)\n",
    "#top_item_idxs = shown_item_ranks[:, recommender.items_shown.shape[1] - k:]\n",
    "top_item_idxs = shown_item_ranks[:, -k:]\n",
    "\n",
    "top_k_items = np.take_along_axis(recommender.items_shown, top_item_idxs, axis=1)\n",
    "\n",
    "#np.take_along_axis(recommender.users.actual_user_scores.value, top_item_ids, axis=1)\n",
    "\n",
    "print(recommender.items_shown)\n",
    "print(shown_item_scores)\n",
    "print(shown_item_ranks)\n",
    "print(top_item_ids)\n",
    "\n",
    "print(top_k_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6]\n",
      " [ 7]\n",
      " [ 3]\n",
      " [12]\n",
      " [ 1]]\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "interactions = recommender.interactions.reshape(recommender.num_users, 1)\n",
    "print(interactions)\n",
    "recall = len(np.where(interactions == top_k_items)[0]) / recommender.num_users\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.14191380e+00  2.05797979e+00 -2.90734031e-01 -3.21875378e-01\n",
      "   1.64575314e+00 -2.55419443e-01  3.48110023e-01 -2.19369368e+00\n",
      "  -3.20387278e-01 -3.97012475e-01 -1.68412571e+00 -4.07926262e-01\n",
      "  -7.24148813e-02 -4.96943205e-01 -3.90776070e-01]\n",
      " [-1.35494813e+00 -5.62433259e-01 -4.31621749e-01 -2.16467514e+00\n",
      "  -3.76389433e-01  1.03274101e+00 -3.82748331e-01  2.29881233e+00\n",
      "  -4.87667695e-01 -2.24900883e+00  8.35125701e-01 -1.47733814e+00\n",
      "  -1.67646907e+00 -1.03272766e+00 -4.66855513e-01]\n",
      " [-1.64125219e+00  5.47461891e-01 -9.38897719e-01  6.98278073e-01\n",
      "   7.57604301e-01  1.44376519e-01  5.34723293e-01 -1.50289861e+00\n",
      "   3.23485875e-02 -2.27994456e-01  3.09597978e-01 -1.01968001e+00\n",
      "  -9.52203821e-01 -5.37110173e-01  1.19390273e+00]\n",
      " [ 7.08681698e-02  1.81433271e-01  4.06857147e-01 -1.82868970e-01\n",
      "   1.22016358e+00 -8.34681900e-02  5.01537684e-01 -9.93660517e-01\n",
      "  -8.90125184e-01  1.40563245e+00 -2.30809812e+00  8.38389488e-01\n",
      "   1.05309238e+00 -3.38738287e-01  7.52203389e-04]\n",
      " [-1.69679120e+00  8.46505085e-01  1.08373781e+00  7.62494567e-01\n",
      "   3.58438868e-02 -1.62224267e-01  7.16541961e-01 -2.00241247e-01\n",
      "   4.25586948e-01 -2.01142390e+00 -1.19518872e-01  1.91763656e-01\n",
      "   4.23402907e-01 -3.77399352e-01  9.18144041e-01]]\n",
      "[[ 1  4  6]\n",
      " [ 7  5 10]\n",
      " [14  4  3]\n",
      " [ 9  4 12]\n",
      " [ 2 14  1]]\n",
      "[[2.05797979 1.64575314 0.34811002]\n",
      " [2.29881233 1.03274101 0.8351257 ]\n",
      " [1.19390273 0.7576043  0.69827807]\n",
      " [1.40563245 1.22016358 1.05309238]\n",
      " [1.08373781 0.91814404 0.84650509]]\n",
      "[[2 1 0]\n",
      " [2 1 0]\n",
      " [2 1 0]\n",
      " [2 1 0]\n",
      " [2 1 0]]\n",
      "[[ 4  1]\n",
      " [ 5  7]\n",
      " [ 4 14]\n",
      " [ 4  9]\n",
      " [14  2]]\n",
      "[-1.35494813 -0.56243326 -0.43162175 -2.16467514 -0.37638943  1.03274101\n",
      " -0.38274833  2.29881233 -0.48766769 -2.24900883  0.8351257  -1.47733814\n",
      " -1.67646907 -1.03272766 -0.46685551]\n"
     ]
    }
   ],
   "source": [
    "shown_item_rel = np.take_along_axis(recommender.predicted_scores.value, recommender.items_shown, axis=1)\n",
    "#actual_rel = np.take_along_axis(recommender.users.actual_user_scores.value, recommender.items_shown, axis=1)\n",
    "\n",
    "\n",
    "shown_item_ranks = np.argsort(shown_item_rel, axis=1)\n",
    "print(recommender.predicted_scores.value)\n",
    "print(recommender.items_shown)\n",
    "print(shown_item_rel)\n",
    "print(shown_item_ranks)\n",
    "top_k_items = np.take_along_axis(recommender.items_shown, top_item_idxs, axis=1)\n",
    "print(top_k_items)\n",
    "\n",
    "print(recommender.predicted_scores.value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shown_item_rel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-337030087436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshown_item_rel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshown_item_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(shown_item_ranks+2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shown_item_rel' is not defined"
     ]
    }
   ],
   "source": [
    "print(shown_item_rel[0])\n",
    "print(shown_item_ranks)\n",
    "#print(shown_item_ranks+2)\n",
    "\n",
    "k=7\n",
    "recommender=mf\n",
    "\n",
    "shown_item_rel = np.take_along_axis(recommender.predicted_scores.value, recommender.items_shown, axis=1)\n",
    "#actual_rel = np.take_along_axis(recommender.users.actual_user_scores.value, recommender.items_shown, axis=1)\n",
    "shown_item_ranks = np.argsort(shown_item_rel, axis=1)\n",
    "dcg = np.sum(shown_item_rel / np.log2(shown_item_ranks+2), axis=1)\n",
    "\n",
    "\n",
    "print(dcg)\n",
    "\n",
    "ideal_ranks=np.tile(np.arange(0,15),(recommender.num_users, recommender.num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(np.arange(0,recommender.items_shown.shape[1]),(recommender.num_users, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20081493 -0.62669818 -0.13549283  0.31272886  0.         -0.43569558\n",
      "   0.24622815 -0.37755385 -1.13868181  0.24763184 -0.31587262 -0.50090452\n",
      "  -0.51111674 -0.06713889 -0.43376564]\n",
      " [-0.31312586  0.06671706  0.11743417 -1.04139937  0.         -0.13851063\n",
      "  -0.31368262  0.57135809 -0.78673142 -0.32282974 -0.2721681  -1.09411609\n",
      "   0.17205193 -0.43886514 -0.65525096]\n",
      " [-0.67811974 -1.04852726  0.01136625  0.32997882  0.         -0.17514042\n",
      "   0.48465576 -0.15774528  0.18974285 -0.05955792 -0.29364017  0.12104795\n",
      "   0.15581012 -0.00600078  0.12704873]\n",
      " [ 1.14875318  0.35770991  0.25861001 -0.07594744  0.         -0.11691005\n",
      "   0.51411     0.62815202 -0.11672326  0.5481165   1.00268376  0.16662842\n",
      "   0.77158909  0.39871142 -0.23208299]\n",
      " [-0.15477756  0.23233256  0.11958448  0.05969266  0.         -0.28521795\n",
      "   0.31953653 -0.50131822 -0.04174253 -0.15995709 -0.44951751 -0.68637632\n",
      "  -1.07559972  0.29270762 -0.97908394]]\n",
      "[[ 8  1 12 11  5 14  7 10  2 13  4  0  6  9  3]\n",
      " [11  3  8 14 13  9  6  0 10  5  4  1  2 12  7]\n",
      " [ 1  0 10  5  7  9 13  4  2 11 14 12  8  3  6]\n",
      " [14  5  8  3  4 11  2  1 13  6  9  7 12 10  0]\n",
      " [12 14 11  7 10  5  9  0  8  4  3  2  1 13  6]]\n",
      "[[0.24622815 0.24763184 0.31272886]\n",
      " [0.11743417 0.17205193 0.57135809]\n",
      " [0.18974285 0.32997882 0.48465576]\n",
      " [0.77158909 1.00268376 1.14875318]\n",
      " [0.23233256 0.29270762 0.31953653]]\n",
      "[[0 1 2 0 1 2 0 1 2]\n",
      " [0 1 2 0 1 2 0 1 2]\n",
      " [0 1 2 0 1 2 0 1 2]\n",
      " [0 1 2 0 1 2 0 1 2]\n",
      " [0 1 2 0 1 2 0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "ideal_rank = np.argsort(recommender.users.actual_user_scores.value)\n",
    "ideal_item_idxs = ideal_rank[:,-3:]\n",
    "ideal_item_rel = np.take_along_axis(recommender.users.actual_user_scores.value, ideal_item_idxs, axis=1)\n",
    "\n",
    "ideal_ranks=np.tile(np.arange(0,recommender.items_shown.shape[1]),(recommender.num_users, 1))\n",
    "\n",
    "idcg = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(recommender.users.actual_user_scores.value)\n",
    "print(ideal_rank)\n",
    "print(ideal_item_rel)\n",
    "print(ideal_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  9,  3],\n",
       "       [ 2, 12,  7],\n",
       "       [ 8,  3,  6],\n",
       "       [12, 10,  0],\n",
       "       [ 1, 13,  6]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_item_ranks[:, recommender.num_items-recommender.items_shown.shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20081493, -0.62669818, -0.13549283,  0.31272886,  0.        ,\n",
       "        -0.43569558,  0.24622815, -0.37755385, -1.13868181,  0.24763184,\n",
       "        -0.31587262, -0.50090452, -0.51111674, -0.06713889, -0.43376564],\n",
       "       [-0.31312586,  0.06671706,  0.11743417, -1.04139937,  0.        ,\n",
       "        -0.13851063, -0.31368262,  0.57135809, -0.78673142, -0.32282974,\n",
       "        -0.2721681 , -1.09411609,  0.17205193, -0.43886514, -0.65525096],\n",
       "       [-0.67811974, -1.04852726,  0.01136625,  0.32997882,  0.        ,\n",
       "        -0.17514042,  0.48465576, -0.15774528,  0.18974285, -0.05955792,\n",
       "        -0.29364017,  0.12104795,  0.15581012, -0.00600078,  0.12704873],\n",
       "       [ 1.14875318,  0.35770991,  0.25861001, -0.07594744,  0.        ,\n",
       "        -0.11691005,  0.51411   ,  0.62815202, -0.11672326,  0.5481165 ,\n",
       "         1.00268376,  0.16662842,  0.77158909,  0.39871142, -0.23208299],\n",
       "       [-0.15477756,  0.23233256,  0.11958448,  0.05969266,  0.        ,\n",
       "        -0.28521795,  0.31953653, -0.50131822, -0.04174253, -0.15995709,\n",
       "        -0.44951751, -0.68637632, -1.07559972,  0.29270762, -0.97908394]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.users.actual_user_scores.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.20081493 -0.62669818 -0.13549283  0.31272886  0.         -0.43569558\n",
      "  0.24622815 -0.37755385 -1.13868181  0.24763184 -0.31587262 -0.50090452\n",
      " -0.51111674 -0.06713889 -0.43376564]\n",
      "[-0.31312586  0.06671706  0.11743417 -1.04139937  0.         -0.13851063\n",
      " -0.31368262  0.57135809 -0.78673142 -0.32282974 -0.2721681  -1.09411609\n",
      "  0.17205193 -0.43886514 -0.65525096]\n",
      "[-0.67811974 -1.04852726  0.01136625  0.32997882  0.         -0.17514042\n",
      "  0.48465576 -0.15774528  0.18974285 -0.05955792 -0.29364017  0.12104795\n",
      "  0.15581012 -0.00600078  0.12704873]\n",
      "[ 8  1 12 11  5 14  7 10  2 13  4  0  6  9  3]\n",
      "[11  3  8 14 13  9  6  0 10  5  4  1  2 12  7]\n",
      "[ 1  0 10  5  7  9 13  4  2 11 14 12  8  3  6]\n",
      "[[ 6  9  3]\n",
      " [ 2 12  7]\n",
      " [ 8  3  6]\n",
      " [12 10  0]\n",
      " [ 1 13  6]]\n"
     ]
    }
   ],
   "source": [
    "k=3\n",
    "recommender=mf\n",
    "\n",
    "\n",
    "actual_item_ranks = np.argsort(recommender.users.actual_user_scores.value, axis=1)\n",
    "#Take the number of users' actual top items according to the number recommended per iteration\n",
    "#actual_top_k_items = np.take(recommender.items_shown, shown_item_ranks[:, recommender.num_items-recommender.items_shown.shape[1]:])\n",
    "\n",
    "#actual_top_k_rel = np.take(recommender.users.actual_user_scores.value, actual_item_ranks[:, recommender.num_items-recommender.items_shown.shape[1]:])\n",
    "top_item_ids = actual_item_ranks[:, recommender.num_items-recommender.items_shown.shape[1]:]\n",
    "top_item_rel = np.take_along_axis(recommender.users.actual_user_scores.value, top_item_ids, axis=1)\n",
    "\n",
    "\n",
    "# print(recommender.users.actual_user_scores.value[0])\n",
    "# print(recommender.users.actual_user_scores.value[1])\n",
    "# print(recommender.users.actual_user_scores.value[2])\n",
    "\n",
    "# print(actual_item_ranks[0])\n",
    "# print(actual_item_ranks[1])\n",
    "# print(actual_item_ranks[2])\n",
    "\n",
    "# print(top_item_ids)\n",
    "\n",
    "# #print(actual_item_ranks[0:2])\n",
    "# print(actual_item_ranks[0:2, recommender.num_items-recommender.items_shown.shape[1]:])\n",
    "\n",
    "# print(actual_top_k_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2, ..., 12, 13, 14],\n",
       "       [ 0,  1,  2, ..., 12, 13, 14],\n",
       "       [ 0,  1,  2, ..., 12, 13, 14],\n",
       "       [ 0,  1,  2, ..., 12, 13, 14],\n",
       "       [ 0,  1,  2, ..., 12, 13, 14]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal_ranks=np.tile(np.arange(0,15),(recommender.num_users, recommender.num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24622815, 0.24763184, 0.31272886],\n",
       "       [0.11743417, 0.17205193, 0.57135809],\n",
       "       [0.18974285, 0.32997882, 0.48465576],\n",
       "       [0.77158909, 1.00268376, 1.14875318],\n",
       "       [0.23233256, 0.29270762, 0.31953653]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take_along_axis(recommender.users.actual_user_scores.value, top_item_ids, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  9,  3],\n",
       "       [ 2, 12,  7],\n",
       "       [ 8,  3,  6],\n",
       "       [12, 10,  0],\n",
       "       [ 1, 13,  6]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_item_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mf.users.actual_user_scores.shape)\n",
    "print(mf.predicted_user_item_scores.shape)\n",
    "\n",
    "actual = np.reshape(mf.users.actual_user_scores.value, (number_of_users*number_of_items, 1))\n",
    "predicted = np.reshape(mf.predicted_user_item_scores, (number_of_users*number_of_items, 1))\n",
    "print(test.shape)\n",
    "\n",
    "plt.hist(actual, alpha=0.7)\n",
    "plt.hist(predicted, alpha=0.7)#predicted scores are more spread out, which kind of makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_error = abs(actual-predicted)\n",
    "\n",
    "plt.hist(abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect measurements about the simulation\n",
    "results = mf.get_measurements()\n",
    "\n",
    "print(\"Results of the simulation:\")\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect measurements about the simulation\n",
    "results = ideal.get_measurements()\n",
    "\n",
    "print(\"Results of the simulation:\")\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = content.get_measurements()\n",
    "\n",
    "print(\"Results of the simulation:\")\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a distribution that hides a subpopulation\n",
    "number_of_attributes = 10\n",
    "number_of_maj_users = 150\n",
    "number_of_min_users = 50\n",
    "\n",
    "maj_user_representation = np.random.normal(1, 2, size=(number_of_maj_users, number_of_attributes))\n",
    "min_user_representation = np.random.normal(0.5, 1.25, size=(number_of_min_users, number_of_attributes))\n",
    "actual_user_representation = np.vstack((maj_user_representation, min_user_representation))\n",
    "split_indices=number_of_maj_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If plotted without respect to the subgroups, preference means look more or less normally distributed\n",
    "plt.hist(actual_user_representation.mean(axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when plotting out mean preferences when accounting for group, we can see a clear distinction in preference\n",
    "plt.hist(maj_user_representation.mean(axis=1), alpha=.7, color='b')\n",
    "plt.hist(min_user_representation.mean(axis=1), alpha=0.7, color='r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering = ContentFiltering(actual_user_representation=actual_user_representation, \n",
    "                             num_attributes=number_of_attributes,\n",
    "                             num_items=500)\n",
    "\n",
    "\n",
    "mse = MSEMeasurement(diagnostics=True)\n",
    "recall=RecallMeasurement()\n",
    "\n",
    "filtering.add_metrics(mse, recall)\n",
    "\n",
    "filtering.startup_and_train(50)\n",
    "filtering.run(450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_diagnostics = filtering.metrics[0].get_diagnostics()\n",
    "mse_beginning = mse_diagnostics.loc[50:, :]\n",
    "mse_beginning.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_histogram(model, split_indices=None):\n",
    "    metric = (\n",
    "                model.predicted_scores.value.mean(axis=1)- model.users.actual_user_scores.value.mean(axis=1))** 2\n",
    "    \n",
    "    colors = [\"blue\", \"orange\", \"red\", \"yellow\", \"green\"]\n",
    "    if split_indices is not None and len(split_indices) > 0:\n",
    "        splits = [0] + split_indices + [metric.size]\n",
    "        for i in range(len(splits) - 1):\n",
    "            values = metric[splits[i] : splits[i + 1]]\n",
    "            plt.hist(values, alpha=0.7, color=colors[i])\n",
    "    else:\n",
    "        plt.hist(metric, bins=\"auto\")\n",
    "        plt.ylabel(\"observation count (total n={})\".format(metric.size))\n",
    "        plt.xlabel(\"mean sqaured error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.startup_and_train(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_histogram(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.run(50)\n",
    "mf.train()\n",
    "mse_histogram(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.run(50)\n",
    "mf.train()\n",
    "mse_histogram(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.run(50)\n",
    "mf.train()\n",
    "mse_histogram(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.run(50)\n",
    "mse_histogram(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.run(50)\n",
    "mse_histogram(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(in_k)\n",
    "print(not_in_k)\n",
    "print(len(model.interactions))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.concatenate((np.ones(len(in_k)), np.zeros(len(not_in_k))), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=mf\n",
    "k=5\n",
    "\n",
    "#split_indices = number_of_maj_users\n",
    "\n",
    "colors = [\"blue\", \"orange\", \"red\", \"yellow\", \"green\"]\n",
    "\n",
    "shown_item_scores = np.take(model.predicted_scores.value, model.items_shown)\n",
    "shown_item_ranks = np.argsort(shown_item_scores, axis=1)\n",
    "top_k_items = np.take(model.items_shown, shown_item_ranks[:, k :])\n",
    "in_k = (np.where(np.isin(model.interactions, top_k_items))[0])\n",
    "not_in_k = (np.where(~np.isin(model.interactions, top_k_items))[0])\n",
    "metric = np.concatenate((np.ones(len(in_k)), np.zeros(len(not_in_k))), axis=None)\n",
    "\n",
    "plt.hist(metric)\n",
    "\n",
    "##Amy, implement this pie chart for recall at k\n",
    "# # Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "# labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n",
    "# sizes = [15, 30, 45, 10]\n",
    "# explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "#         shadow=True, startangle=90)\n",
    "# ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# maj_population_outcomes = metric[:split_indices]\n",
    "# min_population_outcomes = metric[split_indices:]\n",
    "\n",
    "# plt.hist(maj_population_outcomes, color=colors[0])\n",
    "# plt.hist(min_population_outcomes, color=colors[1])\n",
    "\n",
    "\n",
    "\n",
    "# if split_indices is not None:\n",
    "#     splits = [0] + split_indices + [metric.size]\n",
    "#     for i in range(len(splits) - 1):\n",
    "#         values = metric[splits[i] : splits[i + 1]]\n",
    "#         plt.hist(values, alpha=0.7, color=colors[i])\n",
    "\n",
    "# plt.hist(metric, bins=\"auto\")\n",
    "# plt.ylabel(\"observation count (total n={})\".format(metric.size))\n",
    "# plt.xlabel(\"recall at k\")\n",
    "\n",
    "\n",
    "# \n",
    "#     if split_indices is not None and len(split_indices) > 0:\n",
    "#         splits = [0] + split_indices + [metric.size]\n",
    "#         for i in range(len(splits) - 1):\n",
    "#             values = metric[splits[i] : splits[i + 1]]\n",
    "#             plt.hist(values, alpha=0.7, color=colors[i])\n",
    "#     else:\n",
    "#         plt.hist(metric, bins=\"auto\")\n",
    "#         plt.ylabel(\"observation count (total n={})\".format(metric.size))\n",
    "#         plt.xlabel(\"mean sqaured error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(min_population_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(min_population_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_histogram(filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_histogram(filtering, [number_of_maj_users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a bimodal distribution\n",
    "N=500\n",
    "mu, sigma = 1.845, 1\n",
    "mu2, sigma2 = 5.845, 1\n",
    "X1 = np.random.normal(mu, sigma, N)\n",
    "X2 = np.random.normal(mu2, sigma2, N)\n",
    "X_bimodal = np.concatenate([X1, X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print majority / minority outcome stats\n",
    "def majority_minority_outcomes(metric, split_index):\n",
    "    split_indices = [split_index]\n",
    "\n",
    "        \n",
    "    maj_mean = metric.last_observation[:split_index].mean()\n",
    "    maj_std = metric.last_observation[:split_index].std()\n",
    "\n",
    "    min_mean = metric.last_observation[split_index:].mean()\n",
    "    min_std = metric.last_observation[split_index:].std()\n",
    "\n",
    "    print(\"Majority group statistics: \", maj_mean, \"(mean), \", maj_std, \"(std)\")\n",
    "    print(\"Minority group statistics: \", min_mean, \"(mean), \", min_std, \"(std)\")\n",
    "    print()\n",
    "    \n",
    "    metric.hist(split_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we expand on this minimal example to gain a deeper understanding of what happens under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering = ContentFiltering(actual_user_representation=actual_user_representation, \n",
    "                             num_attributes=number_of_attributes,\n",
    "                             num_items=500)\n",
    "\n",
    "\n",
    "mse = MSEMeasurement(diagnostics=True)\n",
    "filtering.add_metrics(mse)\n",
    "\n",
    "filtering.startup_and_train(50)\n",
    "majority_minority_outcomes(mse, number_of_maj_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering.run(450)\n",
    "majority_minority_outcomes(mse, number_of_maj_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bimodal = plt.hist(X_bimodal, bins=30)\n",
    "plt.xlabel('Dependent Variable Value')\n",
    "plt.ylabel('Number of Observations')\n",
    "plt.title('Bimodal Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X_bimodal))\n",
    "print(np.std(X_bimodal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000\n",
    "mu, sigma = 14.99, 4\n",
    "X1 = np.random.normal(mu, sigma, N)\n",
    "X_skew = np.log2(X1)\n",
    "\n",
    "skew = plt.hist(X_skew, bins=30)\n",
    "plt.xlabel('Dependent Variable Value')\n",
    "plt.ylabel('Number of Observations')\n",
    "plt.title('Skewed Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000\n",
    "mu, sigma = 3.85, 2.2\n",
    "normal_dist = np.random.normal(mu, sigma, N)\n",
    "\n",
    "skew = plt.hist(normal_dist, bins=30)\n",
    "plt.xlabel('Dependent Variable Value')\n",
    "plt.ylabel('Number of Observations')\n",
    "plt.title('Normal Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to characterize power, type 1 vs type 2 errors "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trecsEnv",
   "language": "python",
   "name": "trecsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
